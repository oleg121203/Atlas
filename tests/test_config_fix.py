#!/usr/bin/env python3
"""
Ğ¨Ğ²Ğ¸Ğ´ĞºĞ¸Ğ¹ Ñ‚ĞµÑÑ‚ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¸ LLM ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ—
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

def test_config_manager():
    """Test the ConfigManager fix"""
    print("ğŸ§ª Testing ConfigManager...")
    
    try:
        from config_manager import ConfigManager
        config_mgr = ConfigManager()
        
        #Test the new method
        result = config_mgr.set_llm_provider_and_model("gemini", "gemini-1.5-flash")
        if result:
            print("âœ… ConfigManager.set_llm_provider_and_model() works!")
        else:
            print("âŒ ConfigManager.set_llm_provider_and_model() failed!")
            return False
            
        #Test getting current settings
        provider = config_mgr.get_current_provider()
        model = config_mgr.get_current_model()
        print(f"âœ… Current provider: {provider}")
        print(f"âœ… Current model: {model}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ConfigManager test failed: {e}")
        return False

def test_utils_config_manager():
    """Test the utils ConfigManager fix"""
    print("\nğŸ§ª Testing utils ConfigManager...")
    
    try:
        from utils.config_manager import config_manager
        
        #Test the new method
        result = config_manager.set_llm_provider_and_model("gemini", "gemini-1.5-flash")
        if result:
            print("âœ… utils ConfigManager.set_llm_provider_and_model() works!")
        else:
            print("âŒ utils ConfigManager.set_llm_provider_and_model() failed!")
            return False
            
        return True
        
    except Exception as e:
        print(f"âŒ utils ConfigManager test failed: {e}")
        return False

def test_llm_manager():
    """Test LLM Manager with Gemini"""
    print("\nğŸ§ª Testing LLM Manager...")
    
    try:
        #Import necessary modules
        from agents.token_tracker import TokenTracker
        from utils.llm_manager import LLMManager
        
        #Create instances
        token_tracker = TokenTracker()
        llm_manager = LLMManager(token_tracker)
        
        print("âœ… LLM Manager initialized")
        print(f"âœ… Current provider: {llm_manager.current_provider}")
        
        #Test basic chat with a simple message
        messages = [{"role": "user", "content": "ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚! Ğ¯Ğº ÑĞ¿Ñ€Ğ°Ğ²Ğ¸?"}]
        
        print("ğŸ” Testing Gemini chat...")
        try:
            result = llm_manager._chat_gemini(messages, model="gemini-1.5-flash")
            if result and result.response_text:
                print(f"âœ… Gemini response: {result.response_text[:100]}...")
                return True
            else:
                print("âŒ No response from Gemini")
                return False
        except Exception as e:
            print(f"âŒ Gemini chat failed: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ LLM Manager test failed: {e}")
        return False

def main():
    """Run all tests"""
    print("ğŸš€ Running Atlas Configuration Tests...")
    print("=" * 50)
    
    success = True
    
    #Test ConfigManager
    if not test_config_manager():
        success = False
    
    #Test utils ConfigManager
    if not test_utils_config_manager():
        success = False
    
    #Test LLM Manager
    if not test_llm_manager():
        success = False
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ All tests passed! Configuration is working correctly.")
        print("\nğŸš€ You can now start Atlas with: python3 main.py")
    else:
        print("âŒ Some tests failed. Please check the errors above.")
    
    return success

if __name__ == "__main__":
    main()
